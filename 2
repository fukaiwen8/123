import org.apache.spark.{SparkConf, SparkContext}

object RDDFinal {  

    def main(args: Array[String]) = {  // autograder will call this function
        //remember, RDDs only
        val sc = getSC()  // one function to get the sc variable
        val myrdd = getRDD(sc) // on function to get the rdd
        val answer = doFinal(myrdd) // additional functions to do the computation
        saveit(answer, "rdd_final")  // save the rdd to your home directory in HDFS
    }

    def getSC(): SparkContext = {
    val conf = new SparkConf().setAppName("Node Appearance Counter")
    new SparkContext(conf)
    }


    def getRDD(sc:SparkContext): RDD[String] = { // get the big data rdd
sc.textFile("hdfs:///datasets/facebook")
    }

    def doFinal(input: RDD[String]): RDD[(String, (Int, Int))] = {
    val nodeCounts = input.flatMap(line => {
      val nodes = line.split(" ")
      if (nodes.length == 2) {
        val leftNode = nodes(0)
        val rightNode = nodes(1)
        Seq((leftNode, ("Left", 1)), (rightNode, ("Right", 1)))
      } else Seq()
    })

    val aggregatedCounts = nodeCounts
      .map { case (node, (position, count)) => ((node, position), count) }
      .reduceByKey(_ + _)
      .map { case ((node, position), count) => (node, (position, count)) }

    val finalCounts = aggregatedCounts
      .groupByKey()
      .mapValues(iter => {
        var leftCount = 0
        var rightCount = 0
        iter.foreach {
          case ("Left", count)  => leftCount += count
          case ("Right", count) => rightCount += count
        }
        (leftCount, rightCount)
      })
      .filter { case (_, (left, right)) => (left + right) >= 3 }
      .map { case (node, (left, right)) => s"$node\t[$left, $right]" }

    finalCounts

    }
   
    def getTestRDD(sc: SparkContext): RDD[String] = {
 sc.parallelize(Seq(
      "236 186",
      "122 285",
      "236 122",
      "186 285",
      "236 186"
    ))

    }

    def expectedOutput(sc: SparkContext): RDD[(String, (Int, Int))] = {
 sc.parallelize(Seq(
      "236\t[3, 2]",
      "186\t[1, 2]",
      "122\t[1, 1]"
    ))

    }

    def saveit(myrdd: RDD[(String, (Int, Int))], name: String) = {
        myrdd.saveAsTextFile(name)
    }

}


xiu fu zhe ge dai ma
